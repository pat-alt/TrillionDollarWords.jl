var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TrillionDollarWords","category":"page"},{"location":"#TrillionDollarWords","page":"Home","title":"TrillionDollarWords","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TrillionDollarWords.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TrillionDollarWords]","category":"page"},{"location":"#TrillionDollarWords.BaselineModel","page":"Home","title":"TrillionDollarWords.BaselineModel","text":"Struct for the baseline model (i.e. the model presented in the paper).\n\n\n\n\n\n","category":"type"},{"location":"#TrillionDollarWords.BaselineModel-Tuple{Transformers.HuggingFace.HGFRobertaForSequenceClassification, Vector{String}}","page":"Home","title":"TrillionDollarWords.BaselineModel","text":"(mod::BaselineModel)(atomic_model::HGFRobertaForSequenceClassification, queries::Vector{String})\n\nComputes a forward pass of the model on the given queries and returns the logits.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.BaselineModel-Tuple{Transformers.HuggingFace.HGFRobertaModel, Vector{String}}","page":"Home","title":"TrillionDollarWords.BaselineModel","text":"(mod::BaselineModel)(atomic_model::HGFRobertaModel, queries::Vector{String})\n\nComputes a forward pass of the model on the given queries and returns the embeddings.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.BaselineModel-Tuple{Vector{String}}","page":"Home","title":"TrillionDollarWords.BaselineModel","text":"(mod::BaselineModel)(queries::Vector{String})\n\nComputes a forward pass of the model on the given queries and returns either the logits or embeddings depending on whether or not the model was loaded with the head for classification.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.get_embeddings-Tuple{BaselineModel, Vector{String}}","page":"Home","title":"TrillionDollarWords.get_embeddings","text":"get_embeddings(mod::BaselineModel, queries::Vector{String})\n\nComputes a forward pass of the model on the given queries and returns the embeddings.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.get_embeddings-Tuple{Transformers.HuggingFace.HGFRobertaForSequenceClassification, NamedTuple}","page":"Home","title":"TrillionDollarWords.get_embeddings","text":"get_embeddings(atomic_model::HGFRobertaForSequenceClassification, tokens::NamedTuple)\n\nExtends the embeddings function to HGFRobertaForSequenceClassification. Performs a forward pass through the model and returns the embeddings. Then performs a forward pass through the classification head and returns the activations going into the final linear layer.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.get_embeddings-Tuple{Transformers.HuggingFace.HGFRobertaModel, NamedTuple}","page":"Home","title":"TrillionDollarWords.get_embeddings","text":"get_embeddings(atomic_model::HGFRobertaModel, tokens::NamedTuple)\n\nExtends the embeddings function to HGFRobertaModel.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.layerwise_activations-Tuple{BaselineModel, DataFrames.DataFrame}","page":"Home","title":"TrillionDollarWords.layerwise_activations","text":"layerwise_activations(mod::BaselineModel, queries::DataFrame)\n\nComputes a forward pass of the model on the given queries and returns the layerwise activations in a DataFrame where activations are uniquely idendified by the sentence_id. If output_hidden_states=false was passed to load_model (default), only the last layer is returned. If output_hidden_states=true was passed to load_model, all layers are returned. The layer column indicates the layer number.\n\nEach single activation receives its own cell to make it possible to save the output to a CSV file.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.layerwise_activations-Tuple{BaselineModel, Vector{String}}","page":"Home","title":"TrillionDollarWords.layerwise_activations","text":"laywerwise_activations(mod::BaselineModel, queries::Vector{String})\n\nComputes a forward pass of the model on the given queries and returns the layerwise activations for the HGFRobertaModel. If output_hidden_states=false was passed to load_model (default), only the last layer is returned. If output_hidden_states=true was passed to load_model, all layers are returned. If the model is loaded with the head for classification, the activations going into the final linear layer are returned.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_all_data-Tuple{}","page":"Home","title":"TrillionDollarWords.load_all_data","text":"load_all_data()\n\nLoad the combined dataset from the artifact. This dataset combines all sentences and the market data used in the paper.\n\nThe sentence_id column is the unique identifier of the sentence.\nThe doc_id column is the unique identifier of the document.\nThe date column is the date of the event.\nThe event_type column is the type of event (meeting minutes, speech, or press conference).\nThe labels in label are predicted by the model proposed in the paper.\n\nWe use the RoBERTa-large model finetuned on the combined data to label all the filtered sentences in the meeting minutes, speeches, and press conferences.\n\nThe sentence column is the sentence itself. \nThe score column is the softmax probability of the label.\nThe speaker column is the speaker of the sentence (if applicable).\nThe value columns is the value of the market indicator (CPI, PPI, or UST).\nThe indicator column is the market indicator (CPI, PPI, or UST).\nThe maturity column is the maturity of the UST (if applicable).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_all_sentences-Tuple{}","page":"Home","title":"TrillionDollarWords.load_all_sentences","text":"load_all_sentences()\n\nLoad the dataset with all sentences from the artifact. This is the complete dataset with sentences from press conferences, meeting minutes, and speeches. \n\nThe sentence_id column is the unique identifier of the sentence.\nThe doc_id column is the unique identifier of the document.\nThe date column is the date of the event.\nThe event_type column is the type of event (meeting minutes, speech, or press conference).\nThe labels in label are predicted by the model proposed in the paper.\n\nWe use the RoBERTa-large model finetuned on the combined data to label all the filtered sentences in the meeting minutes, speeches, and press conferences.\n\nThe sentence column is the sentence itself. \nThe score column is the softmax probability of the label.\nThe speaker column is the speaker of the sentence (if applicable).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_cpi_data-Tuple{}","page":"Home","title":"TrillionDollarWords.load_cpi_data","text":"load_cpi_data()\n\nLoad the CPI data from the artifact. This is the CPI data used in the paper.\n\nThe date column is the date of the event.\nThe value columns is the value of the market indicator (CPI, PPI, or UST).\nThe indicator column is the market indicator (CPI, PPI, or UST).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_market_data-Tuple{}","page":"Home","title":"TrillionDollarWords.load_market_data","text":"load_market_data()\n\nLoad the combined market data from the artifact. This dataset combines the CPI, PPI and UST data used in the paper.\n\nThe date column is the date of the event.\nThe value columns is the value of the market indicator (CPI, PPI, or UST).\nThe indicator column is the market indicator (CPI, PPI, or UST).\nThe maturity column is the maturity of the UST (if applicable).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_model-Tuple{}","page":"Home","title":"TrillionDollarWords.load_model","text":"load_model\n\nLoads the model presented in the paper from HuggingFace. If load_head is true, the model is loaded with the head (i.e. the final layer) for classification. If load_head is false, the model is loaded without the head. The latter is useful for fine-tuning the model on a different task or in case the classification head is not needed. Accepts any additional keyword arguments that are accepted by Transformers.HuggingFace.HGFConfig.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_ppi_data-Tuple{}","page":"Home","title":"TrillionDollarWords.load_ppi_data","text":"load_ppi_data()\n\nLoad the PPI data from the artifact. This is the PPI data used in the paper.\n\nThe date column is the date of the event.\nThe value columns is the value of the market indicator (CPI, PPI, or UST).\nThe indicator column is the market indicator (CPI, PPI, or UST).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_training_sentences-Tuple{}","page":"Home","title":"TrillionDollarWords.load_training_sentences","text":"load_training_sentences()\n\nLoad the dataset with training sentences from the artifact. This is a combined dataset containing sentences from press conferences, meeting minutes, and speeches.\n\nThe sentence column is the sentence itself. \nThe year column is the year of the event.\nThe labels in label are the manually annotated labels from the paper.\nThe seed column is the seed that was used to split the data into train and test set in the paper. \nThe sentence_splitting column indicates if the sentence was split or not (see the paper for details).\nThe event_type column is the type of event (meeting minutes, speech, or press conference).\nThe split column indicates if the sentence is in the train or test set.\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.load_ust_data-Tuple{}","page":"Home","title":"TrillionDollarWords.load_ust_data","text":"load_ust_data()\n\nLoad the UST (treasury yields) data from the artifact. This is the UST data used in the paper.\n\nThe date column is the date of the event.\nThe value columns is the value of the market indicator (CPI, PPI, or UST).\nThe indicator column is the market indicator (CPI, PPI, or UST).\nThe maturity column is the maturity of the UST (if applicable).\n\n\n\n\n\n","category":"method"},{"location":"#TrillionDollarWords.prepare_probe-Tuple{DataFrames.DataFrame}","page":"Home","title":"TrillionDollarWords.prepare_probe","text":"prepare_probe(outcome_data::DataFrame; layer::Int=24, value_var::Symbol=:value)\n\nPrepare data for a linear probe. The outcome_data should be a DataFrame with a sentence_id column, which should contain unique values. There should also be a column containing the outcome variable. By default, this column is assumed to be called value, but this can be changed with the value_var argument. The layer argument indicates which layer to use for the probe. The default is the last layer (24).\n\n\n\n\n\n","category":"method"}]
}
